{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import utls as utl\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GLOVE\n"
     ]
    }
   ],
   "source": [
    "#Load GLOVE vectors\n",
    "filepath_glove = '/home/avaratharaj/Glove/glove.6B/glove.6B.100d.txt'\n",
    "glove_vocab = []\n",
    "glove_embd=[]\n",
    "embedding_dict = {}\n",
    " \n",
    "file = open(filepath_glove,'r',encoding='UTF-8')\n",
    "for line in file.readlines():\n",
    "    row = line.strip().split(' ')\n",
    "    vocab_word = row[0]\n",
    "    glove_vocab.append(vocab_word)\n",
    "    embed_vector = [float(i) for i in row[1:]] # convert to list of float\n",
    "    embedding_dict[vocab_word]=embed_vector\n",
    "file.close()\n",
    "  \n",
    "print('Loaded GLOVE')\n",
    " \n",
    "glove_vocab_size = len(glove_vocab)\n",
    "embedding_dim = len(embed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionaries(words):\n",
    "    count = collections.Counter(words).most_common() #creates list of word/count pairs;\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary) #len(dictionary) increases each iteration\n",
    "        reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('open_response_filter.csv')\n",
    "#data= data.loc[data['problem_id']==1096508]\n",
    "for index, row in data.iterrows():\n",
    "    sentence=row['answer_text']\n",
    "    sentence=sentence.replace(\".\",\" \")\n",
    "    sentence=sentence.replace(\"+\",\" + \")\n",
    "    sentence=sentence.replace(\"/\",\" / \")\n",
    "    sentence=sentence.replace(\"*\",\" * \")\n",
    "    sentence=sentence.replace(\"-\",\" - \")\n",
    "    sentence=sentence.replace(\"(\",\" ( \")\n",
    "    sentence=sentence.replace(\")\",\" ) \")\n",
    "    sentence=sentence.replace(\"'\",\" \")\n",
    "    sentence=sentence.replace(\"=\",\" = \")\n",
    "    sentence=sentence.replace(\":\",\" : \")\n",
    "    sentence=sentence.replace(\"<\",\" < \")\n",
    "    sentence=sentence.replace(\">\",\" > \")\n",
    "    sentence=sentence.replace(\"^\",\" ^ \")\n",
    "    sentence=sentence.replace(\",\",\" \")\n",
    "    sentence=sentence.replace(u'\\xa0', u' ')\n",
    "    sentence=sentence.replace(u'\\r\\n', u'')\n",
    "    sentence=sentence.replace('  ', ' ')\n",
    "    sentence=sentence.replace('   ', ' ')\n",
    "    sentence=sentence.replace('-', ' ')\n",
    "    \n",
    "    \n",
    "    sentence=sentence.lower()\n",
    "    sentence=sentence.strip()\n",
    "    data.set_value(index,'answer_text',sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting floats to integers\n",
    "list(set(data['correct']))\n",
    "data.loc[data['correct']==0.0,'correct']=0\n",
    "data.loc[data['correct']==0.25,'correct']=1\n",
    "data.loc[data['correct']==0.5,'correct']=2\n",
    "data.loc[data['correct']==0.75,'correct']=3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(data['correct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get messages and sentiment labels\n",
    "messages = data.answer_text.values\n",
    "labels = data.correct.values\n",
    "\n",
    "messages = np.array([utl.preprocess_ST_message(message) for message in messages])\n",
    "\n",
    "messages=messages.tolist()\n",
    "labels=labels.tolist()\n",
    "for i in messages:\n",
    "    if(len(i)>600):\n",
    "        indx=messages.index(i)\n",
    "        del messages[indx]\n",
    "        del labels[indx]\n",
    "full_lexicon = \" \".join(messages).split()\n",
    "dictionary, reverse_dictionary = build_dictionaries(full_lexicon)\n",
    "messages_lens = Counter([len(x) for x in messages])\n",
    "print(\"Zero-length messages: {}\".format(messages_lens[0]))\n",
    "print(\"Maximum message length: {}\".format(max(messages_lens)))\n",
    "print(\"Average message length: {}\".format(np.mean([len(x) for x in messages])))\n",
    "messages, labels = utl.drop_empty_messages(messages, labels)\n",
    "messages = utl.encode_ST_messages(messages, dictionary)\n",
    "labels = utl.encode_ST_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1897"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['rea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embedding array\n",
    "import random\n",
    "from scipy import spatial\n",
    "  \n",
    "doc_vocab_size = len(dictionary)\n",
    "dict_as_list = sorted(dictionary.items(), key = lambda x : x[1])\n",
    " \n",
    "embeddings_tmp=[]\n",
    " \n",
    "for i in range(doc_vocab_size):\n",
    "    item = dict_as_list[i][0]\n",
    "    if item in glove_vocab:\n",
    "        embeddings_tmp.append(embedding_dict[item])\n",
    "    else:\n",
    "        rand_num = np.random.uniform(low=0.0, high=0.0,size=embedding_dim)\n",
    "        embeddings_tmp.append(rand_num)\n",
    " \n",
    "    # final embedding array corresponds to dictionary of words in the document\n",
    "embedding = np.asarray(embeddings_tmp)\n",
    " \n",
    "# create tree so that we can later search for closest vector to prediction\n",
    "tree = spatial.KDTree(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    \"\"\"\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, None], name='labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs_, labels_, keep_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_layer(inputs_, vocab_size, embed_size):\n",
    "    \"\"\"\n",
    "    Create the embedding layer\n",
    "    \"\"\"\n",
    "    #embedding = tf.Variable(tf.random_uniform((vocab_size, embed_size), -1, 1))\n",
    "    #embed = tf.nn.embedding_lookup(embedding, inputs_)\n",
    "    with tf.name_scope(\"embedding\"):\n",
    "        W = tf.Variable(tf.constant(0.0, shape=[doc_vocab_size, embedding_dim]), trainable=True, name=\"W\")\n",
    "        embedding_placeholder = tf.placeholder(tf.float32, [doc_vocab_size, embedding_dim])\n",
    "        embedding_init = W.assign(embedding_placeholder)\n",
    "        embed = tf.nn.embedding_lookup(W,inputs_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_layers(lstm_sizes, embed, keep_prob_, batch_size):\n",
    "    \"\"\"\n",
    "    Create the LSTM layers\n",
    "    \"\"\"\n",
    "    lstms = [tf.contrib.rnn.BasicLSTMCell(size) for size in lstm_sizes]\n",
    "    # Add dropout to the cell\n",
    "    drops = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_) for lstm in lstms]\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(drops)\n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    lstm_outputs, final_state = tf.nn.dynamic_rnn(cell, embed, initial_state=initial_state)\n",
    "    \n",
    "    return initial_state, lstm_outputs, cell, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate):\n",
    "    \"\"\"\n",
    "    Create the Loss function and Optimizer\n",
    "    \"\"\"\n",
    "    predictions = tf.contrib.layers.fully_connected(lstm_outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "    loss = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    optimzer = tf.train.AdadeltaOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    return predictions, loss, optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_accuracy(predictions, labels_):\n",
    "    \"\"\"\n",
    "    Create accuracy\n",
    "    \"\"\"\n",
    "    #print(\"INSIDE BUILD ACCURACY\")\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.float32), labels_)\n",
    "    #print(\"Predictions:\",predictions)\n",
    "    #print(\"Labels:\",labels_)\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    accuracy = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(predictions,labels_))))\n",
    "    #print(\"ACC:\",accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_network(lstm_sizes, vocab_size, embed_size, epochs, batch_size,\n",
    "                            learning_rate, keep_prob, train_x, val_x, train_y, val_y):\n",
    "    \n",
    "    inputs_, labels_, keep_prob_ = model_inputs()\n",
    "    #embed = build_embedding_layer(inputs_, vocab_size, embed_size)\n",
    "    with tf.name_scope(\"embedding\"):\n",
    "        W = tf.Variable(tf.constant(0.0, shape=[doc_vocab_size, embedding_dim]), trainable=True, name=\"W\")\n",
    "        embedding_placeholder = tf.placeholder(tf.float32, [doc_vocab_size, embedding_dim])\n",
    "        embedding_init = W.assign(embedding_placeholder)\n",
    "        embed = tf.nn.embedding_lookup(W,inputs_)\n",
    "    \n",
    "    initial_state, lstm_outputs, lstm_cell, final_state = build_lstm_layers(lstm_sizes, embed, keep_prob_, batch_size)\n",
    "    predictions, loss, optimizer = build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate)\n",
    "    accuracy = build_accuracy(predictions, labels_)\n",
    "    #print(\"Pred:\",predictions)\n",
    "    #print(\"lables:\",labels_)\n",
    "    #print(\"Embed:\")\n",
    "    #print(embed)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(embedding_init, feed_dict={embedding_placeholder: embedding}) #added\n",
    "        n_batches = len(train_x)//batch_size\n",
    "        for e in range(epochs):\n",
    "            state = sess.run(initial_state)\n",
    "            \n",
    "            train_acc = []\n",
    "            for ii, (x, y) in enumerate(utl.get_batches(train_x, train_y, batch_size), 1):\n",
    "                #print(\"Train_x\")\n",
    "                #print(x)\n",
    "                #print(\"Shape:\",x.shape)\n",
    "                #print(\"Size of x before:\",x.shape)\n",
    "                x_lens = Counter([len(x_) for x_ in x])\n",
    "                #print(\"X_lens:\",x_lens)\n",
    "                #print(\"max:\",max(x_lens))\n",
    "                x = utl.zero_pad_messages(x, seq_len=max(x_lens))\n",
    "                \n",
    "                #print(\"Size of x after:\",x.shape)\n",
    "                feed = {inputs_: x,\n",
    "                        labels_: y[:, None],\n",
    "                        keep_prob_: keep_prob,\n",
    "                        initial_state: state}\n",
    "                loss_, state, _,  batch_acc = sess.run([loss, final_state, optimizer, accuracy], feed_dict=feed)\n",
    "                train_acc.append(batch_acc)\n",
    "                \"\"\" \n",
    "                if (ii + 1) % n_batches == 0:\n",
    "                     \n",
    "                    val_acc = []\n",
    "                    val_state = sess.run(lstm_cell.zero_state(batch_size, tf.float32))\n",
    "                    for xx, yy in utl.get_batches(val_x, val_y, batch_size):\n",
    "                        \n",
    "                        xx_lens = Counter([len(x_) for x_ in xx])\n",
    "                        xx = utl.zero_pad_messages(xx, seq_len=max(xx_lens))\n",
    "                        feed = {inputs_: xx,\n",
    "                                labels_: yy[:, None],\n",
    "                                keep_prob_: 1,\n",
    "                                initial_state: val_state}\n",
    "                        val_batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                        val_acc.append(val_batch_acc)\n",
    "                \"\"\"        \n",
    "        val_acc = []\n",
    "        val_state = sess.run(lstm_cell.zero_state(batch_size, tf.float32))\n",
    "        for xx, yy in utl.get_batches(val_x, val_y, batch_size):\n",
    "\n",
    "            xx_lens = Counter([len(x_) for x_ in xx])\n",
    "            xx = utl.zero_pad_messages(xx, seq_len=max(xx_lens))\n",
    "            feed = {inputs_: xx,\n",
    "                    labels_: yy[:, None],\n",
    "                    keep_prob_: 1,\n",
    "                    initial_state: val_state}\n",
    "            val_batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "            val_acc.append(val_batch_acc)\n",
    "        saver.save(sess, \"checkpoints/sentiment.ckpt\")\n",
    "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "          \"Batch: {}/{}...\".format(ii+1, n_batches),\n",
    "          \"Train Loss: {:.3f}...\".format(loss_),\n",
    "          \"Train Accruacy: {:.3f}...\".format(np.mean(train_acc)),\n",
    "          \"Val Accuracy: {:.3f}\".format(np.mean(val_acc)))\n",
    "    return val_acc,np.mean(val_acc)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Inputs and Hyperparameters\n",
    "lstm_sizes = [10]\n",
    "vocab_size = doc_vocab_size #len(vocab_to_int) + 1 #add one for padding\n",
    "embed_size = embedding_dim\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "learning_rate = 0.1\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob id: 1415683\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.028... Train Accruacy: 0.232... Val Accuracy: 0.245\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.034... Train Accruacy: 0.245... Val Accuracy: 0.238\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.014... Train Accruacy: 0.264... Val Accuracy: 0.239\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.012... Train Accruacy: 0.261... Val Accuracy: 0.306\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.026... Train Accruacy: 0.201... Val Accuracy: 0.154\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.064... Train Accruacy: 0.267... Val Accuracy: 0.231\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.069... Train Accruacy: 0.271... Val Accuracy: 0.270\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.172... Train Accruacy: 0.360... Val Accuracy: 0.418\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.211... Train Accruacy: 0.333... Val Accuracy: 0.261\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.069... Train Accruacy: 0.259... Val Accuracy: 0.251\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.143... Train Accruacy: 0.328... Val Accuracy: 0.265\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.061... Train Accruacy: 0.228... Val Accuracy: 0.228\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.036... Train Accruacy: 0.222... Val Accuracy: 0.231\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.020... Train Accruacy: 0.264... Val Accuracy: 0.250\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.093... Train Accruacy: 0.302... Val Accuracy: 0.216\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.025... Train Accruacy: 0.388... Val Accuracy: 0.355\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.093... Train Accruacy: 0.275... Val Accuracy: 0.338\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.179... Train Accruacy: 0.352... Val Accuracy: 0.307\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.097... Train Accruacy: 0.238... Val Accuracy: 0.227\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.166... Train Accruacy: 0.316... Val Accuracy: 0.262\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.050... Train Accruacy: 0.312... Val Accuracy: 0.368\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.091... Train Accruacy: 0.252... Val Accuracy: 0.229\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.037... Train Accruacy: 0.277... Val Accuracy: 0.253\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.022... Train Accruacy: 0.259... Val Accuracy: 0.327\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.104... Train Accruacy: 0.260... Val Accuracy: 0.268\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.104... Train Accruacy: 0.291... Val Accuracy: 0.256\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.072... Train Accruacy: 0.267... Val Accuracy: 0.333\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.220... Train Accruacy: 0.480... Val Accuracy: 0.465\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.036... Train Accruacy: 0.272... Val Accuracy: 0.206\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.088... Train Accruacy: 0.351... Val Accuracy: 0.281\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.183... Train Accruacy: 0.398... Val Accuracy: 0.359\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.129... Train Accruacy: 0.278... Val Accuracy: 0.221\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.083... Train Accruacy: 0.203... Val Accuracy: 0.293\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.167... Train Accruacy: 0.393... Val Accuracy: 0.434\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.188... Train Accruacy: 0.241... Val Accuracy: 0.260\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.054... Train Accruacy: 0.328... Val Accuracy: 0.302\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.141... Train Accruacy: 0.386... Val Accuracy: 0.406\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.039... Train Accruacy: 0.327... Val Accuracy: 0.364\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.243... Train Accruacy: 0.232... Val Accuracy: 0.272\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.070... Train Accruacy: 0.226... Val Accuracy: 0.197\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.056... Train Accruacy: 0.298... Val Accuracy: 0.344\n",
      "Epoch: 20/20... Batch: 42/41... Train Loss: 0.255... Train Accruacy: 0.331... Val Accuracy: 0.323\n",
      "Test Rmse: 0.323394\n",
      "Prob id: 1225220\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.047... Train Accruacy: 0.228... Val Accuracy: 0.298\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.096... Train Accruacy: 0.260... Val Accuracy: 0.273\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.068... Train Accruacy: 0.232... Val Accuracy: 0.337\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.002... Train Accruacy: 0.186... Val Accuracy: 0.265\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.086... Train Accruacy: 0.314... Val Accuracy: 0.335\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.089... Train Accruacy: 0.293... Val Accuracy: 0.359\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.102... Train Accruacy: 0.317... Val Accuracy: 0.340\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.017... Train Accruacy: 0.225... Val Accuracy: 0.290\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.079... Train Accruacy: 0.277... Val Accuracy: 0.377\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.207... Train Accruacy: 0.323... Val Accuracy: 0.346\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.098... Train Accruacy: 0.279... Val Accuracy: 0.419\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.085... Train Accruacy: 0.275... Val Accuracy: 0.271\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.100... Train Accruacy: 0.298... Val Accuracy: 0.349\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.048... Train Accruacy: 0.305... Val Accuracy: 0.357\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.074... Train Accruacy: 0.303... Val Accuracy: 0.521\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.025... Train Accruacy: 0.275... Val Accuracy: 0.291\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.058... Train Accruacy: 0.282... Val Accuracy: 0.379\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.025... Train Accruacy: 0.188... Val Accuracy: 0.198\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.157... Train Accruacy: 0.256... Val Accuracy: 0.298\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.119... Train Accruacy: 0.350... Val Accuracy: 0.366\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.009... Train Accruacy: 0.232... Val Accuracy: 0.384\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.027... Train Accruacy: 0.253... Val Accuracy: 0.289\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.008... Train Accruacy: 0.267... Val Accuracy: 0.325\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.029... Train Accruacy: 0.286... Val Accuracy: 0.398\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.034... Train Accruacy: 0.239... Val Accuracy: 0.330\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.040... Train Accruacy: 0.244... Val Accuracy: 0.286\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.043... Train Accruacy: 0.355... Val Accuracy: 0.363\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.193... Train Accruacy: 0.353... Val Accuracy: 0.385\n",
      "Test Rmse: 0.385005\n",
      "Prob id: 1249297\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.009... Train Accruacy: 0.224... Val Accuracy: 0.286\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.037... Train Accruacy: 0.224... Val Accuracy: 0.341\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.034... Train Accruacy: 0.236... Val Accuracy: 0.239\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.064... Train Accruacy: 0.229... Val Accuracy: 0.134\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.023... Train Accruacy: 0.145... Val Accuracy: 0.130\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.037... Train Accruacy: 0.225... Val Accuracy: 0.194\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.072... Train Accruacy: 0.227... Val Accuracy: 0.216\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.065... Train Accruacy: 0.199... Val Accuracy: 0.203\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.002... Train Accruacy: 0.193... Val Accuracy: 0.344\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.010... Train Accruacy: 0.203... Val Accuracy: 0.209\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.007... Train Accruacy: 0.122... Val Accuracy: 0.190\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.034... Train Accruacy: 0.226... Val Accuracy: 0.404\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.018... Train Accruacy: 0.234... Val Accuracy: 0.184\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.046... Train Accruacy: 0.257... Val Accuracy: 0.208\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.020... Train Accruacy: 0.222... Val Accuracy: 0.204\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.031... Train Accruacy: 0.237... Val Accuracy: 0.275\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.029... Train Accruacy: 0.189... Val Accuracy: 0.310\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.047... Train Accruacy: 0.210... Val Accuracy: 0.493\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.010... Train Accruacy: 0.173... Val Accuracy: 0.266\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.148... Train Accruacy: 0.281... Val Accuracy: 0.327\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.055... Train Accruacy: 0.192... Val Accuracy: 0.237\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.004... Train Accruacy: 0.185... Val Accuracy: 0.267\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.026... Train Accruacy: 0.209... Val Accuracy: 0.224\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.006... Train Accruacy: 0.130... Val Accuracy: 0.197\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.015... Train Accruacy: 0.192... Val Accuracy: 0.133\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.102... Train Accruacy: 0.277... Val Accuracy: 0.442\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.017... Train Accruacy: 0.208... Val Accuracy: 0.172\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.058... Train Accruacy: 0.228... Val Accuracy: 0.430\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.001... Train Accruacy: 0.169... Val Accuracy: 0.190\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.200... Train Accruacy: 0.309... Val Accuracy: 0.401\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.008... Train Accruacy: 0.245... Val Accuracy: 0.506\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.132... Train Accruacy: 0.226... Val Accuracy: 0.303\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.052... Train Accruacy: 0.270... Val Accuracy: 0.353\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.020... Train Accruacy: 0.259... Val Accuracy: 0.259\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.170... Train Accruacy: 0.303... Val Accuracy: 0.287\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.065... Train Accruacy: 0.257... Val Accuracy: 0.254\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.059... Train Accruacy: 0.222... Val Accuracy: 0.296\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.072... Train Accruacy: 0.276... Val Accuracy: 0.295\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.207... Train Accruacy: 0.248... Val Accuracy: 0.326\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.087... Train Accruacy: 0.266... Val Accuracy: 0.354\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.146... Train Accruacy: 0.233... Val Accuracy: 0.224\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.007... Train Accruacy: 0.220... Val Accuracy: 0.402\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.185... Train Accruacy: 0.196... Val Accuracy: 0.306\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.121... Train Accruacy: 0.252... Val Accuracy: 0.236\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.025... Train Accruacy: 0.292... Val Accuracy: 0.375\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.019... Train Accruacy: 0.294... Val Accuracy: 0.283\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.055... Train Accruacy: 0.236... Val Accuracy: 0.209\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.047... Train Accruacy: 0.277... Val Accuracy: 0.292\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.256... Train Accruacy: 0.171... Val Accuracy: 0.288\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.115... Train Accruacy: 0.298... Val Accuracy: 0.270\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.011... Train Accruacy: 0.222... Val Accuracy: 0.196\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.031... Train Accruacy: 0.244... Val Accuracy: 0.306\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.083... Train Accruacy: 0.187... Val Accuracy: 0.154\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.025... Train Accruacy: 0.213... Val Accuracy: 0.191\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.023... Train Accruacy: 0.200... Val Accuracy: 0.294\n",
      "Epoch: 20/20... Batch: 56/55... Train Loss: 0.006... Train Accruacy: 0.197... Val Accuracy: 0.209\n",
      "Test Rmse: 0.208589\n",
      "Prob id: 1462311\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.371... Train Accruacy: 0.624... Val Accuracy: 0.588\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.023... Train Accruacy: 0.350... Val Accuracy: 0.406\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.144... Train Accruacy: 0.426... Val Accuracy: 0.439\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.281... Train Accruacy: 0.573... Val Accuracy: 0.581\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.080... Train Accruacy: 0.396... Val Accuracy: 0.386\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.120... Train Accruacy: 0.363... Val Accuracy: 0.412\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.341... Train Accruacy: 0.437... Val Accuracy: 0.559\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.088... Train Accruacy: 0.397... Val Accuracy: 0.481\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.260... Train Accruacy: 0.384... Val Accuracy: 0.405\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.277... Train Accruacy: 0.437... Val Accuracy: 0.385\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.258... Train Accruacy: 0.409... Val Accuracy: 0.462\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.311... Train Accruacy: 0.465... Val Accuracy: 0.488\n",
      "Test Rmse: 0.487509\n",
      "Prob id: 1391167\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.117... Train Accruacy: 0.376... Val Accuracy: 0.356\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.126... Train Accruacy: 0.349... Val Accuracy: 0.210\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.145... Train Accruacy: 0.393... Val Accuracy: 0.403\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.177... Train Accruacy: 0.301... Val Accuracy: 0.282\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.078... Train Accruacy: 0.389... Val Accuracy: 0.360\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.064... Train Accruacy: 0.285... Val Accuracy: 0.249\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.023... Train Accruacy: 0.311... Val Accuracy: 0.303\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.153... Train Accruacy: 0.462... Val Accuracy: 0.497\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.056... Train Accruacy: 0.226... Val Accuracy: 0.243\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.105... Train Accruacy: 0.321... Val Accuracy: 0.272\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.029... Train Accruacy: 0.289... Val Accuracy: 0.413\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.023... Train Accruacy: 0.307... Val Accuracy: 0.324\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.086... Train Accruacy: 0.403... Val Accuracy: 0.425\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.044... Train Accruacy: 0.296... Val Accuracy: 0.293\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.320... Train Accruacy: 0.348... Val Accuracy: 0.337\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.142... Train Accruacy: 0.375... Val Accuracy: 0.373\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.164... Train Accruacy: 0.348... Val Accuracy: 0.342\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.089... Train Accruacy: 0.311... Val Accuracy: 0.328\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.130... Train Accruacy: 0.391... Val Accuracy: 0.398\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.047... Train Accruacy: 0.323... Val Accuracy: 0.285\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.008... Train Accruacy: 0.300... Val Accuracy: 0.273\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.073... Train Accruacy: 0.356... Val Accuracy: 0.287\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.143... Train Accruacy: 0.357... Val Accuracy: 0.380\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.144... Train Accruacy: 0.346... Val Accuracy: 0.365\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.106... Train Accruacy: 0.308... Val Accuracy: 0.278\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.193... Train Accruacy: 0.370... Val Accuracy: 0.335\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.226... Train Accruacy: 0.322... Val Accuracy: 0.306\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.152... Train Accruacy: 0.516... Val Accuracy: 0.538\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.063... Train Accruacy: 0.399... Val Accuracy: 0.436\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.049... Train Accruacy: 0.280... Val Accuracy: 0.242\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.217... Train Accruacy: 0.343... Val Accuracy: 0.332\n",
      "Epoch: 20/20... Batch: 32/31... Train Loss: 0.019... Train Accruacy: 0.269... Val Accuracy: 0.293\n",
      "Test Rmse: 0.29316\n",
      "Prob id: 1391168\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.117... Train Accruacy: 0.319... Val Accuracy: 0.299\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.036... Train Accruacy: 0.272... Val Accuracy: 0.298\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.014... Train Accruacy: 0.293... Val Accuracy: 0.254\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.149... Train Accruacy: 0.386... Val Accuracy: 0.406\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.019... Train Accruacy: 0.221... Val Accuracy: 0.184\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.042... Train Accruacy: 0.292... Val Accuracy: 0.374\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.110... Train Accruacy: 0.344... Val Accuracy: 0.311\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.102... Train Accruacy: 0.285... Val Accuracy: 0.295\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.259... Train Accruacy: 0.342... Val Accuracy: 0.390\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.138... Train Accruacy: 0.374... Val Accuracy: 0.353\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.139... Train Accruacy: 0.284... Val Accuracy: 0.276\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.079... Train Accruacy: 0.282... Val Accuracy: 0.256\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.084... Train Accruacy: 0.264... Val Accuracy: 0.241\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.103... Train Accruacy: 0.254... Val Accuracy: 0.238\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.049... Train Accruacy: 0.273... Val Accuracy: 0.295\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.045... Train Accruacy: 0.339... Val Accuracy: 0.318\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.009... Train Accruacy: 0.253... Val Accuracy: 0.295\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.099... Train Accruacy: 0.306... Val Accuracy: 0.296\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.014... Train Accruacy: 0.228... Val Accuracy: 0.229\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.115... Train Accruacy: 0.244... Val Accuracy: 0.349\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.093... Train Accruacy: 0.250... Val Accuracy: 0.271\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.042... Train Accruacy: 0.288... Val Accuracy: 0.330\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.099... Train Accruacy: 0.398... Val Accuracy: 0.349\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.155... Train Accruacy: 0.274... Val Accuracy: 0.221\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.035... Train Accruacy: 0.301... Val Accuracy: 0.259\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.270... Train Accruacy: 0.320... Val Accuracy: 0.352\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.215... Train Accruacy: 0.410... Val Accuracy: 0.348\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.127... Train Accruacy: 0.324... Val Accuracy: 0.325\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.144... Train Accruacy: 0.411... Val Accuracy: 0.419\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.113... Train Accruacy: 0.286... Val Accuracy: 0.356\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.162... Train Accruacy: 0.297... Val Accuracy: 0.244\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.025... Train Accruacy: 0.244... Val Accuracy: 0.205\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.045... Train Accruacy: 0.314... Val Accuracy: 0.284\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.013... Train Accruacy: 0.324... Val Accuracy: 0.286\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.119... Train Accruacy: 0.345... Val Accuracy: 0.372\n",
      "Epoch: 20/20... Batch: 36/35... Train Loss: 0.024... Train Accruacy: 0.204... Val Accuracy: 0.242\n",
      "Test Rmse: 0.242471\n",
      "Prob id: 1415753\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.231... Train Accruacy: 0.480... Val Accuracy: 0.483\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.088... Train Accruacy: 0.289... Val Accuracy: 0.233\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.419... Train Accruacy: 0.390... Val Accuracy: 0.312\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.105... Train Accruacy: 0.290... Val Accuracy: 0.356\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.242... Train Accruacy: 0.399... Val Accuracy: 0.345\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.290... Train Accruacy: 0.470... Val Accuracy: 0.470\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.145... Train Accruacy: 0.405... Val Accuracy: 0.385\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.172... Train Accruacy: 0.382... Val Accuracy: 0.408\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.116... Train Accruacy: 0.345... Val Accuracy: 0.365\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.159... Train Accruacy: 0.334... Val Accuracy: 0.321\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.187... Train Accruacy: 0.324... Val Accuracy: 0.253\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.227... Train Accruacy: 0.324... Val Accuracy: 0.319\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.125... Train Accruacy: 0.381... Val Accuracy: 0.431\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.386... Train Accruacy: 0.547... Val Accuracy: 0.612\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.179... Train Accruacy: 0.362... Val Accuracy: 0.258\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.059... Train Accruacy: 0.309... Val Accuracy: 0.292\n",
      "Epoch: 20/20... Batch: 17/16... Train Loss: 0.043... Train Accruacy: 0.344... Val Accuracy: 0.281\n",
      "Test Rmse: 0.280728\n",
      "Prob id: 1415762\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.182... Train Accruacy: 0.382... Val Accuracy: 0.357\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.091... Train Accruacy: 0.399... Val Accuracy: 0.465\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.374... Train Accruacy: 0.553... Val Accuracy: 0.511\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.303... Train Accruacy: 0.413... Val Accuracy: 0.379\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.168... Train Accruacy: 0.427... Val Accuracy: 0.472\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.189... Train Accruacy: 0.430... Val Accuracy: 0.460\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.101... Train Accruacy: 0.309... Val Accuracy: 0.389\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.115... Train Accruacy: 0.417... Val Accuracy: 0.519\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.227... Train Accruacy: 0.438... Val Accuracy: 0.349\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.127... Train Accruacy: 0.400... Val Accuracy: 0.585\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.310... Train Accruacy: 0.417... Val Accuracy: 0.504\n",
      "Epoch: 20/20... Batch: 12/11... Train Loss: 0.313... Train Accruacy: 0.356... Val Accuracy: 0.434\n",
      "Test Rmse: 0.434063\n",
      "Prob id: 1226843\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.017... Train Accruacy: 0.303... Val Accuracy: 0.305\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.024... Train Accruacy: 0.232... Val Accuracy: 0.238\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.198... Train Accruacy: 0.320... Val Accuracy: 0.322\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.149... Train Accruacy: 0.322... Val Accuracy: 0.342\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.062... Train Accruacy: 0.293... Val Accuracy: 0.381\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.227... Train Accruacy: 0.480... Val Accuracy: 0.449\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.199... Train Accruacy: 0.302... Val Accuracy: 0.388\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.075... Train Accruacy: 0.316... Val Accuracy: 0.373\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.051... Train Accruacy: 0.298... Val Accuracy: 0.319\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.024... Train Accruacy: 0.212... Val Accuracy: 0.294\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.043... Train Accruacy: 0.275... Val Accuracy: 0.302\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.185... Train Accruacy: 0.382... Val Accuracy: 0.404\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.227... Train Accruacy: 0.362... Val Accuracy: 0.365\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.163... Train Accruacy: 0.351... Val Accuracy: 0.388\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.017... Train Accruacy: 0.161... Val Accuracy: 0.247\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.071... Train Accruacy: 0.333... Val Accuracy: 0.330\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.158... Train Accruacy: 0.362... Val Accuracy: 0.379\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.068... Train Accruacy: 0.373... Val Accuracy: 0.376\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.061... Train Accruacy: 0.292... Val Accuracy: 0.299\n",
      "Test Rmse: 0.299472\n",
      "Prob id: 1423460\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.103... Train Accruacy: 0.321... Val Accuracy: 0.271\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.126... Train Accruacy: 0.202... Val Accuracy: 0.145\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.130... Train Accruacy: 0.283... Val Accuracy: 0.147\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.251... Train Accruacy: 0.370... Val Accuracy: 0.278\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.103... Train Accruacy: 0.292... Val Accuracy: 0.351\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.094... Train Accruacy: 0.381... Val Accuracy: 0.484\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.161... Train Accruacy: 0.441... Val Accuracy: 0.436\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.071... Train Accruacy: 0.285... Val Accuracy: 0.324\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.161... Train Accruacy: 0.278... Val Accuracy: 0.245\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.204... Train Accruacy: 0.312... Val Accuracy: 0.342\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.097... Train Accruacy: 0.224... Val Accuracy: 0.221\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.092... Train Accruacy: 0.368... Val Accuracy: 0.488\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.238... Train Accruacy: 0.368... Val Accuracy: 0.404\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.154... Train Accruacy: 0.366... Val Accuracy: 0.499\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.176... Train Accruacy: 0.347... Val Accuracy: 0.312\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.124... Train Accruacy: 0.254... Val Accuracy: 0.207\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.087... Train Accruacy: 0.326... Val Accuracy: 0.293\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.108... Train Accruacy: 0.311... Val Accuracy: 0.296\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.299... Train Accruacy: 0.458... Val Accuracy: 0.481\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.151... Train Accruacy: 0.355... Val Accuracy: 0.351\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.198... Train Accruacy: 0.362... Val Accuracy: 0.358\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.114... Train Accruacy: 0.386... Val Accuracy: 0.222\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.182... Train Accruacy: 0.333... Val Accuracy: 0.383\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.200... Train Accruacy: 0.352... Val Accuracy: 0.344\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.163... Train Accruacy: 0.319... Val Accuracy: 0.331\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.034... Train Accruacy: 0.313... Val Accuracy: 0.287\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.142... Train Accruacy: 0.351... Val Accuracy: 0.348\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.056... Train Accruacy: 0.245... Val Accuracy: 0.231\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.211... Train Accruacy: 0.307... Val Accuracy: 0.234\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.136... Train Accruacy: 0.294... Val Accuracy: 0.409\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.269... Train Accruacy: 0.370... Val Accuracy: 0.388\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.211... Train Accruacy: 0.310... Val Accuracy: 0.256\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.244... Train Accruacy: 0.361... Val Accuracy: 0.331\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.110... Train Accruacy: 0.387... Val Accuracy: 0.414\n",
      "Test Rmse: 0.413917\n",
      "Prob id: 1423463\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.012... Train Accruacy: 0.339... Val Accuracy: 0.372\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.140... Train Accruacy: 0.339... Val Accuracy: 0.375\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.223... Train Accruacy: 0.226... Val Accuracy: 0.178\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.171... Train Accruacy: 0.295... Val Accuracy: 0.310\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.053... Train Accruacy: 0.353... Val Accuracy: 0.297\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.142... Train Accruacy: 0.382... Val Accuracy: 0.346\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.127... Train Accruacy: 0.325... Val Accuracy: 0.333\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.065... Train Accruacy: 0.252... Val Accuracy: 0.187\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.287... Train Accruacy: 0.402... Val Accuracy: 0.397\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.014... Train Accruacy: 0.230... Val Accuracy: 0.423\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.212... Train Accruacy: 0.480... Val Accuracy: 0.462\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.110... Train Accruacy: 0.260... Val Accuracy: 0.492\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.195... Train Accruacy: 0.442... Val Accuracy: 0.476\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.057... Train Accruacy: 0.302... Val Accuracy: 0.290\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.309... Train Accruacy: 0.330... Val Accuracy: 0.451\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.128... Train Accruacy: 0.352... Val Accuracy: 0.292\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.175... Train Accruacy: 0.382... Val Accuracy: 0.359\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.022... Train Accruacy: 0.231... Val Accuracy: 0.352\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.119... Train Accruacy: 0.318... Val Accuracy: 0.330\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.094... Train Accruacy: 0.389... Val Accuracy: 0.414\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.022... Train Accruacy: 0.335... Val Accuracy: 0.281\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.017... Train Accruacy: 0.285... Val Accuracy: 0.405\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.084... Train Accruacy: 0.283... Val Accuracy: 0.432\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.208... Train Accruacy: 0.408... Val Accuracy: 0.441\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.140... Train Accruacy: 0.327... Val Accuracy: 0.329\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.100... Train Accruacy: 0.369... Val Accuracy: 0.365\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.311... Train Accruacy: 0.427... Val Accuracy: 0.450\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.106... Train Accruacy: 0.187... Val Accuracy: 0.125\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.154... Train Accruacy: 0.353... Val Accuracy: 0.325\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.267... Train Accruacy: 0.331... Val Accuracy: 0.317\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.079... Train Accruacy: 0.272... Val Accuracy: 0.499\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.027... Train Accruacy: 0.331... Val Accuracy: 0.294\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.228... Train Accruacy: 0.408... Val Accuracy: 0.406\n",
      "Epoch: 20/20... Batch: 34/33... Train Loss: 0.119... Train Accruacy: 0.280... Val Accuracy: 0.239\n",
      "Test Rmse: 0.23949\n",
      "Prob id: 1423465\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.268... Train Accruacy: 0.416... Val Accuracy: 0.433\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.335... Train Accruacy: 0.566... Val Accuracy: 0.543\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.080... Train Accruacy: 0.411... Val Accuracy: 0.445\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.197... Train Accruacy: 0.465... Val Accuracy: 0.480\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.267... Train Accruacy: 0.460... Val Accuracy: 0.398\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.339... Train Accruacy: 0.338... Val Accuracy: 0.432\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.181... Train Accruacy: 0.476... Val Accuracy: 0.454\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.490... Train Accruacy: 0.519... Val Accuracy: 0.531\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.092... Train Accruacy: 0.532... Val Accuracy: 0.553\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.045... Train Accruacy: 0.283... Val Accuracy: 0.495\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.272... Train Accruacy: 0.448... Val Accuracy: 0.506\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.288... Train Accruacy: 0.534... Val Accuracy: 0.539\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.098... Train Accruacy: 0.497... Val Accuracy: 0.530\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.044... Train Accruacy: 0.250... Val Accuracy: 0.276\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.484... Train Accruacy: 0.569... Val Accuracy: 0.577\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.298... Train Accruacy: 0.496... Val Accuracy: 0.558\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.072... Train Accruacy: 0.395... Val Accuracy: 0.388\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.065... Train Accruacy: 0.369... Val Accuracy: 0.350\n",
      "Epoch: 20/20... Batch: 19/18... Train Loss: 0.202... Train Accruacy: 0.312... Val Accuracy: 0.306\n",
      "Test Rmse: 0.306284\n",
      "Prob id: 1397357\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.099... Train Accruacy: 0.392... Val Accuracy: 0.393\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.276... Train Accruacy: 0.432... Val Accuracy: 0.435\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.026... Train Accruacy: 0.341... Val Accuracy: 0.295\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.109... Train Accruacy: 0.377... Val Accuracy: 0.384\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.069... Train Accruacy: 0.262... Val Accuracy: 0.262\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.034... Train Accruacy: 0.218... Val Accuracy: 0.172\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.139... Train Accruacy: 0.324... Val Accuracy: 0.322\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.171... Train Accruacy: 0.405... Val Accuracy: 0.430\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.241... Train Accruacy: 0.383... Val Accuracy: 0.492\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.148... Train Accruacy: 0.427... Val Accuracy: 0.483\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.291... Train Accruacy: 0.446... Val Accuracy: 0.526\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.146... Train Accruacy: 0.365... Val Accuracy: 0.404\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.055... Train Accruacy: 0.405... Val Accuracy: 0.317\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.063... Train Accruacy: 0.327... Val Accuracy: 0.521\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.241... Train Accruacy: 0.350... Val Accuracy: 0.426\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.178... Train Accruacy: 0.343... Val Accuracy: 0.326\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.190... Train Accruacy: 0.325... Val Accuracy: 0.391\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.060... Train Accruacy: 0.373... Val Accuracy: 0.365\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.241... Train Accruacy: 0.315... Val Accuracy: 0.263\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.245... Train Accruacy: 0.399... Val Accuracy: 0.355\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.108... Train Accruacy: 0.411... Val Accuracy: 0.380\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.045... Train Accruacy: 0.346... Val Accuracy: 0.397\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.095... Train Accruacy: 0.352... Val Accuracy: 0.403\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.045... Train Accruacy: 0.283... Val Accuracy: 0.207\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.308... Train Accruacy: 0.429... Val Accuracy: 0.496\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.042... Train Accruacy: 0.434... Val Accuracy: 0.436\n",
      "Epoch: 20/20... Batch: 27/26... Train Loss: 0.166... Train Accruacy: 0.469... Val Accuracy: 0.391\n",
      "Test Rmse: 0.391377\n",
      "Prob id: 1415796\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.095... Train Accruacy: 0.278... Val Accuracy: 0.247\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.203... Train Accruacy: 0.407... Val Accuracy: 0.447\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.136... Train Accruacy: 0.456... Val Accuracy: 0.502\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.122... Train Accruacy: 0.299... Val Accuracy: 0.304\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.027... Train Accruacy: 0.237... Val Accuracy: 0.341\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.075... Train Accruacy: 0.387... Val Accuracy: 0.350\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.156... Train Accruacy: 0.314... Val Accuracy: 0.278\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.115... Train Accruacy: 0.336... Val Accuracy: 0.413\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.086... Train Accruacy: 0.421... Val Accuracy: 0.406\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.242... Train Accruacy: 0.427... Val Accuracy: 0.421\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.080... Train Accruacy: 0.316... Val Accuracy: 0.250\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.238... Train Accruacy: 0.398... Val Accuracy: 0.356\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.210... Train Accruacy: 0.352... Val Accuracy: 0.355\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.013... Train Accruacy: 0.322... Val Accuracy: 0.327\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.188... Train Accruacy: 0.364... Val Accuracy: 0.433\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.256... Train Accruacy: 0.415... Val Accuracy: 0.520\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.144... Train Accruacy: 0.292... Val Accuracy: 0.523\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.237... Train Accruacy: 0.455... Val Accuracy: 0.474\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.166... Train Accruacy: 0.375... Val Accuracy: 0.365\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.157... Train Accruacy: 0.395... Val Accuracy: 0.325\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.175... Train Accruacy: 0.407... Val Accuracy: 0.390\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.168... Train Accruacy: 0.423... Val Accuracy: 0.394\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.021... Train Accruacy: 0.325... Val Accuracy: 0.319\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.033... Train Accruacy: 0.330... Val Accuracy: 0.328\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.127... Train Accruacy: 0.310... Val Accuracy: 0.341\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.052... Train Accruacy: 0.347... Val Accuracy: 0.408\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.267... Train Accruacy: 0.333... Val Accuracy: 0.326\n",
      "Epoch: 20/20... Batch: 28/27... Train Loss: 0.150... Train Accruacy: 0.351... Val Accuracy: 0.454\n",
      "Test Rmse: 0.454458\n",
      "Prob id: 1428086\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.018... Train Accruacy: 0.306... Val Accuracy: 0.378\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.082... Train Accruacy: 0.357... Val Accuracy: 0.306\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.192... Train Accruacy: 0.449... Val Accuracy: 0.418\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.044... Train Accruacy: 0.351... Val Accuracy: 0.396\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.408... Train Accruacy: 0.457... Val Accuracy: 0.467\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.140... Train Accruacy: 0.444... Val Accuracy: 0.435\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.171... Train Accruacy: 0.426... Val Accuracy: 0.430\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.060... Train Accruacy: 0.396... Val Accuracy: 0.370\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.177... Train Accruacy: 0.371... Val Accuracy: 0.442\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.318... Train Accruacy: 0.430... Val Accuracy: 0.408\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.222... Train Accruacy: 0.445... Val Accuracy: 0.472\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.181... Train Accruacy: 0.364... Val Accuracy: 0.405\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.238... Train Accruacy: 0.474... Val Accuracy: 0.477\n",
      "Epoch: 20/20... Batch: 14/13... Train Loss: 0.482... Train Accruacy: 0.525... Val Accuracy: 0.492\n",
      "Test Rmse: 0.491993\n",
      "Prob id: 1487480\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index -1 of dimension 1 out of bounds.\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n\t [[Node: rnn/while/Exit_2/_49 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_987_rnn/while/Exit_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'strided_slice', defined at:\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-ea3e3f1443ba>\", line 82, in <module>\n    learning_rate, keep_prob, train_x, test_x, train_y, test_y)\n  File \"<ipython-input-17-8f431cba5bd3>\", line 13, in build_and_train_network\n    predictions, loss, optimizer = build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate)\n  File \"<ipython-input-15-7bafacdc2442>\", line 5, in build_cost_fn_and_opt\n    predictions = tf.contrib.layers.fully_connected(lstm_outputs[:, -1], 1, activation_fn=tf.sigmoid)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 538, in _SliceHelper\n    name=name)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 706, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5430, in strided_slice\n    name=name)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): slice index -1 of dimension 1 out of bounds.\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n\t [[Node: rnn/while/Exit_2/_49 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_987_rnn/while/Exit_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index -1 of dimension 1 out of bounds.\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n\t [[Node: rnn/while/Exit_2/_49 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_987_rnn/while/Exit_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ea3e3f1443ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             test_rmse,mean_test_rmse=build_and_train_network(lstm_sizes, vocab_size, embed_size, epochs, batch_size,\n\u001b[0;32m---> 82\u001b[0;31m                                 learning_rate, keep_prob, train_x, test_x, train_y, test_y)\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;31m#print(\"Test rmse:\",test_rmse,\"Mean test rmse\",mean_test_rmse)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtest_rmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_test_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-8f431cba5bd3>\u001b[0m in \u001b[0;36mbuild_and_train_network\u001b[0;34m(lstm_sizes, vocab_size, embed_size, epochs, batch_size, learning_rate, keep_prob, train_x, val_x, train_y, val_y)\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0mkeep_prob_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         initial_state: state}\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \"\"\" \n",
      "\u001b[0;32m/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index -1 of dimension 1 out of bounds.\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n\t [[Node: rnn/while/Exit_2/_49 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_987_rnn/while/Exit_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'strided_slice', defined at:\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-ea3e3f1443ba>\", line 82, in <module>\n    learning_rate, keep_prob, train_x, test_x, train_y, test_y)\n  File \"<ipython-input-17-8f431cba5bd3>\", line 13, in build_and_train_network\n    predictions, loss, optimizer = build_cost_fn_and_opt(lstm_outputs, labels_, learning_rate)\n  File \"<ipython-input-15-7bafacdc2442>\", line 5, in build_cost_fn_and_opt\n    predictions = tf.contrib.layers.fully_connected(lstm_outputs[:, -1], 1, activation_fn=tf.sigmoid)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 538, in _SliceHelper\n    name=name)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 706, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5430, in strided_slice\n    name=name)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/avaratharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): slice index -1 of dimension 1 out of bounds.\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n\t [[Node: rnn/while/Exit_2/_49 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_987_rnn/while/Exit_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "    # read data from csv file\n",
    "data1 = pd.read_csv('open_response_filter.csv')\n",
    "results=[]\n",
    "problem_ids=list(set(data['problem_id']))\n",
    "    for p in problem_ids:\n",
    "        print(\"Prob id:\",p)\n",
    "        data= data1.loc[data1['problem_id']==p]\n",
    "        for index, row in data.iterrows():\n",
    "            sentence=row['answer_text']\n",
    "            sentence=sentence.replace(\".\",\" \")\n",
    "            sentence=sentence.replace(\"+\",\" + \")\n",
    "            sentence=sentence.replace(\"/\",\" / \")\n",
    "            sentence=sentence.replace(\"*\",\" * \")\n",
    "            sentence=sentence.replace(\"-\",\" - \")\n",
    "            sentence=sentence.replace(\"(\",\" ( \")\n",
    "            sentence=sentence.replace(\")\",\" ) \")\n",
    "            sentence=sentence.replace(\"'\",\" \")\n",
    "            sentence=sentence.replace(\"=\",\" = \")\n",
    "            sentence=sentence.replace(\":\",\" : \")\n",
    "            sentence=sentence.replace(\"<\",\" < \")\n",
    "            sentence=sentence.replace(\">\",\" > \")\n",
    "            sentence=sentence.replace(\"^\",\" ^ \")\n",
    "            sentence=sentence.replace(\",\",\" \")\n",
    "            sentence=sentence.replace(u'\\xa0', u' ')\n",
    "            sentence=sentence.replace(u'\\r\\n', u'')\n",
    "            sentence=sentence.replace('  ', ' ')\n",
    "            sentence=sentence.replace('   ', ' ')\n",
    "            sentence=sentence.replace('-', ' ')\n",
    "\n",
    "\n",
    "            sentence=sentence.lower()\n",
    "            sentence=sentence.strip()\n",
    "            data.set_value(index,'answer_text',sentence)\n",
    "        # get messages and sentiment labels\n",
    "        messages = data.answer_text.values\n",
    "        labels = data.correct.values\n",
    "\n",
    "\n",
    "        #messages=data['answer_text']\n",
    "        #labels= data['correct']\n",
    "        # View sample of messages with sentiment\n",
    "\n",
    "        #for i in range(10):\n",
    "            #print(\"Messages: {}...\".format(messages[i]),\n",
    "                  #\"Correctnes: {}\".format(labels[i]))\n",
    "        messages = np.array([utl.preprocess_ST_message(message) for message in messages])\n",
    "        messages=messages.tolist()\n",
    "        labels=labels.tolist()\n",
    "        for i in messages:\n",
    "            if(len(i)>600):\n",
    "                indx=messages.index(i)\n",
    "                del messages[indx]\n",
    "                del labels[indx]\n",
    "        \n",
    "        #Create dictionary and reverse dictionary with word ids\n",
    "\n",
    "        full_lexicon = \" \".join(messages).split()\n",
    "\n",
    "        #messages = utl.encode_ST_messages(messages, dictionary)\n",
    "        messages = utl.encode_ST_messages(messages, dictionary)\n",
    "        labels = utl.encode_ST_labels(labels)\n",
    "        #for i in range(10):\n",
    "        #    print(\"Messages: {}...\".format(messages[i]))\n",
    "        \n",
    "        \n",
    "        loo = LeaveOneOut()\n",
    "\n",
    "\n",
    "        #print(loo.get_n_splits(messages))\n",
    "\n",
    "\n",
    "        counter = 0\n",
    "        test_rmse=[]\n",
    "        for train_index, test_index in loo.split(messages):\n",
    "            #print(\"Counter=\",counter)\n",
    "            counter=counter+1\n",
    "            train_x,test_x = messages[train_index], messages[test_index]\n",
    "            train_y,test_y = labels[train_index], labels[test_index]\n",
    "\n",
    "            with tf.Graph().as_default():\n",
    "                test_rmse,mean_test_rmse=build_and_train_network(lstm_sizes, vocab_size, embed_size, epochs, batch_size,\n",
    "                                    learning_rate, keep_prob, train_x, test_x, train_y, test_y)\n",
    "                #print(\"Test rmse:\",test_rmse,\"Mean test rmse\",mean_test_rmse)\n",
    "                test_rmse.append(mean_test_rmse)\n",
    "                #test_network('checkpoints', batch_size, test_x, test_y)\n",
    "        print(\"Test Rmse:\",np.mean(np.array(test_rmse)))\n",
    "        results.append([p,len(messages),np.mean(np.array(test_rmse))])\n",
    "result_df=pd.DataFrame(results)\n",
    "result_df.to_csv('Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
